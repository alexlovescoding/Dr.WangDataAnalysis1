{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(epoch):\n",
    "    return datetime.datetime.fromtimestamp(epoch/1000).strftime(\"%Y-%m-%d\")\n",
    "# first convert from milliseconds to seconds, and then convert format from time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each line of data as csv file   \n",
    "data = []\n",
    "fileNum = 2\n",
    "while fileNum < 115: \n",
    "    with open('data/logs-insights-results-' + str(fileNum) + '.csv') as f:\n",
    "        for line in csv.DictReader(f, fieldnames=('timestamp', 'message')):\n",
    "            data.append(line)\n",
    "        fileNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75092"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimension of data\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track               65673\n",
      "profile_set_once     9419\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check type\n",
    "tp = []\n",
    "for i in range(len(data)):\n",
    "    tp.append(data[i].get(\"type\",None))\n",
    "tp = pd.DataFrame({\"type\":tp})\n",
    "print(tp[\"type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$pageview                32620\n",
      "btnClick                 13866\n",
      "index_leave              10394\n",
      "demo_leave                3411\n",
      "about_leave               1032\n",
      "courses_leave              906\n",
      "formSubmit                 791\n",
      "courses_play_leave         747\n",
      "click_send_cellphone       600\n",
      "verify_cellphone_code      563\n",
      "clickSubmit                513\n",
      "page_close                 230\n",
      "Name: event, dtype: int64\n",
      "event    9419\n",
      "dtype: int64\n",
      "{'distinct_id': '595466e9a8e733434ce08de16e927d985e0b5d48', 'lib': {'$lib': 'js', '$lib_method': 'code', '$lib_version': '1.6.20'}, 'properties': {'$os': 'windows', '$model': 'pc', '$os_version': '6.1', '$screen_height': 800, '$screen_width': 1280, '$lib': 'js', '$lib_version': '1.6.20', '$browser': 'chrome', '$browser_version': '56', '$latest_referrer': '', '$latest_referrer_host': '', '$latest_utm_source': 'baidu', '$latest_utm_medium': 'cpc', '$latest_utm_campaign': '通用词', '$latest_utm_content': '通用-用户画像', '$latest_utm_term': '用户画像', '_latest_ch': 'demo', '_session_referrer': 'https://www.baidu.com/baidu.php', '_session_referrer_host': 'www.baidu.com', 'session_page_url': 'https://www.sensorsdata.cn/?utm_source=baidu&utm_medium=cpc&utm_term=%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F&utm_content=%E9%80%9A%E7%94%A8%2D%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F&utm_campaign=%E9%80%9A%E7%94%A8%E8%AF%8D', 'pageUrl': 'https://sensorsdata.cn/?ch=demo', 'pageStayTime': 5.692, 'pagePosition': 2, '$is_first_day': True, '$is_first_time': False, '$ip': '219.135.131.99'}, 'type': 'track', 'event': 'index_leave', '_nocache': '0654392402996', 'time': 1488791047953}\n"
     ]
    }
   ],
   "source": [
    "# check event\n",
    "event = []\n",
    "for i in range(len(data)):\n",
    "    event.append(data[i].get(\"event\",None))\n",
    "event = pd.DataFrame({\"event\":event})\n",
    "print(event[\"event\"].value_counts())\n",
    "print(event.isnull().sum()) # 9419 entries contain null event = number of profile_set_once.\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['distinct_id', 'lib', 'properties', 'type', 'event', '_nocache', 'time'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This decodes to message into different attributes:\n",
    "#### account: the account of the user \n",
    "#### sourceIP: the ip address of the sender of the message\n",
    "#### destIP: the receiver of the message\n",
    "#### interface: the log stream of the message\n",
    "#### srcPort: internet port of sender\n",
    "#### dstPort: internet port of receiver\n",
    "#### protocol: the network protocol used to communicate the message\n",
    "#### byte: the size of the message\n",
    "#### packets: number of segments of the message\n",
    "#### timeStamp: exact time it took to send the message\n",
    "#### status: either \"ACCEPT\" or \"REJECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "time = []\n",
    "account = []\n",
    "sourceIP = []\n",
    "destIP = []\n",
    "interface = []\n",
    "srcPort = []\n",
    "dstPort = []\n",
    "protocol = []\n",
    "byte = []\n",
    "packets = []\n",
    "timeStamp = []\n",
    "status = []\n",
    "\n",
    "na = None\n",
    "i = 1\n",
    "\n",
    "while i < len(data):\n",
    "    msg = data[i].get('message',na)\n",
    "    # for messages with no data will get filtered out here\n",
    "    if 'ACCEPT' in msg or 'REJECT' in msg:\n",
    "        timeTokens = data[i].get('timestamp',na).split()\n",
    "        date.append(timeTokens[0])\n",
    "        time.append(timeTokens[1])\n",
    "        tokens = msg.split()\n",
    "        account.append(tokens[1])\n",
    "        interface.append(tokens[2])\n",
    "        sourceIP.append(tokens[3])\n",
    "        destIP.append(tokens[4])\n",
    "        #storing actions\n",
    "        temp = 5\n",
    "        tempStr = ''\n",
    "        while(tokens[temp+1] != \"OK\"):\n",
    "            tempStr = tempStr + tokens[temp] + ' '\n",
    "            temp += 1\n",
    "        actionTokens = tempStr.split()\n",
    "        srcPort.append(actionTokens[0])\n",
    "        dstPort.append(actionTokens[1])\n",
    "        protocol.append(actionTokens[2])\n",
    "        packets.append(actionTokens[3])\n",
    "        byte.append(actionTokens[4])\n",
    "        timeStamp.append(int(actionTokens[6]) - int(actionTokens[5]))\n",
    "        status.append(tokens[temp])\n",
    "    i += 1\n",
    "print(date[0])\n",
    "print(time[0])\n",
    "print(account[0])\n",
    "print(interface[0])\n",
    "print(sourceIP[0])\n",
    "print(destIP[0])\n",
    "print(status[0])\n",
    "print(srcPort[0])\n",
    "print(dstPort[0])\n",
    "print(protocol[0])\n",
    "print(packets[0])\n",
    "print(byte[0])\n",
    "print(timeStamp[0])\n",
    "print(len(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"date\":date,\n",
    "    \"time\":time,\n",
    "    \"account\":account,\n",
    "    \"interface\":interface,\n",
    "    \"sourceIP\":sourceIP,\n",
    "    \"destIP\":destIP,\n",
    "    \"srcPort\":srcPort,\n",
    "    \"dstPort\":dstPort,\n",
    "    \"protocol\":protocol,\n",
    "    \"packets\":packets,\n",
    "    \"byte\":byte,\n",
    "    \"timeStamp\":timeStamp,\n",
    "    \"status\":status\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['packets'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueIP = set()\n",
    "for i in sourceIP:\n",
    "    uniqueIP.add(i)\n",
    "for i in destIP:\n",
    "    uniqueIP.add(i)\n",
    "print(\"There are \" + str(len(uniqueIP)) + \" unique IP address.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sourceIP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sourceIP.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.destIP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.destIP.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.account.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sourceIP.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check on the source ip address for the rejected \n",
    "df[df['status'].str.contains(\"REJECT\")].sourceIP.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['status'].str.contains(\"REJECT\")].destIP.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what time are all the rejections come from\n",
    "df[df['status'].str.contains(\"REJECT\")].time.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why is this time has so many rejects? check for the ip address from this time\n",
    "df[df['time'].str.contains(\"19:41:37.000\")].sourceIP.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['sourceIP'].str.contains(\"10.3.252.33\")].status.value_counts().plot.barh()\n",
    "#use lambda to calculate percentage of accept/reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The IP address 10.3.252.33 seems suspicious as it sends 2000+ requests in 1 second, \n",
    "# and most of the rejections come to this address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the source ip from the unknown account\n",
    "df[df['account'].str.contains(\"unknown\")].sourceIP.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['account'].str.contains(\"unknown\")].destIP.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what time are all the unknowns come from? Seems evenly out\n",
    "df[df['account'].str.contains(\"unknown\")].time.value_counts().head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the unknown accounts are accepted\n",
    "df[df['account'].str.contains(\"unknown\")].status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the unknowns seem to be the inside communication among the server's ip address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Logistic Regression Model\n",
    "#### Encode categorical columns to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_category = ['account','protocol','status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df[col_category], columns=col_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [u'account_430405884063',u'account_unknown',\n",
    "                     u'srcPort',u'dstPort',u'protocol_1',u'protocol_132',u'protocol_17',\n",
    "                     u'protocol_41',u'protocol_6',u'byte',\n",
    "                     u'timeStamp',u'status_ACCEPT',u'status_REJECT']\n",
    "X = df[selected_features].values\n",
    "y = df['timeStamp'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train test splbit function from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I am stuck here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import logistic regression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize model by providing parameters\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "clf = LogisticRegression(C=1.0, penalty='l2')\n",
    "\n",
    "# Fit a model by providing X and y from training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on the training data\n",
    "y_train_pred = clf.predict(X_train)\n",
    "p_train_pred = clf.predict_proba(X_train)[:,1]\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred = clf.predict(X_test)\n",
    "p_test_pred = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the metric scores for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics functions from sklearn\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to print metric scores    \n",
    "def get_performance_metrics(y_train, y_train_pred, y_test, y_test_pred, threshold=0.5):\n",
    "    metric_names = ['AUC','Accuracy','Precision','Recall','f1-score']\n",
    "    metric_values_train = [roc_auc_score(y_train, y_train_pred),\n",
    "                    accuracy_score(y_train, y_train_pred>threshold),\n",
    "                    precision_score(y_train, y_train_pred>threshold),\n",
    "                    recall_score(y_train, y_train_pred>threshold),\n",
    "                    f1_score(y_train, y_train_pred>threshold)\n",
    "                   ]\n",
    "    metric_values_test = [roc_auc_score(y_test, y_test_pred),\n",
    "                    accuracy_score(y_test, y_test_pred>threshold),\n",
    "                    precision_score(y_test, y_test_pred>threshold),\n",
    "                    recall_score(y_test, y_test_pred>threshold),\n",
    "                    f1_score(y_test, y_test_pred>threshold)\n",
    "                   ]\n",
    "    all_metrics = pd.DataFrame({'metrics':metric_names,\n",
    "                                'train':metric_values_train,\n",
    "                                'test':metric_values_test},columns=['metrics','train','test']).set_index('metrics')\n",
    "    print(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_train, y_train_pred, y_test, y_test_pred, title):\n",
    "    roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr_train, tpr_train, color='green',\n",
    "             lw=lw, label='ROC Train (AUC = %0.4f)' % roc_auc_train)\n",
    "    plt.plot(fpr_test, tpr_test, color='darkorange',\n",
    "             lw=lw, label='ROC Test (AUC = %0.4f)' % roc_auc_test)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('ROC_' + title + '.png', bbox_inches=\"tight\",dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model results\n",
    "get_performance_metrics(y_train, p_train_pred, y_test, p_test_pred)\n",
    "plot_roc_curve(y_train, p_train_pred, y_test, p_test_pred, 'LgReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeffs = pd.DataFrame(list(zip(selected_features, clf.coef_.flatten()))).sort_values(by=[1], ascending=False)\n",
    "df_coeffs.columns = ['feature', 'coeff']\n",
    "df_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "#plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "ax = df_coeffs.plot.barh(align='center',width=0.35)\n",
    "t = np.arange(X.shape[1])\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_coeffs['feature'])\n",
    "rcParams['figure.figsize'] = 12, 12\n",
    "plt.savefig('features.png',bbox_inches=\"tight\",dpi=500)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    '''\n",
    "    Code from sklearn example.\n",
    "    '''\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    # Show confusion matrix in a separate window\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Area Under Curve (AUC) of the Logistic Regression is: {}\".format(roc_auc_score(y_test, y_test_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
